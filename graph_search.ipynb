{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "import heapq\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "# Load FastText embeddings\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English model\n",
    "en_model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x10b788280>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.reduce_model(en_model, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from functools import lru_cache\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomi_owolabi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomi_owolabi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_VALUES_PATH = \"similarity_data/sim.values.txt\"\n",
    "SIM_WORDS_PATH = \"similarity_data/sim.words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDistance():\n",
    "    def __init__(self, emb_model, words_path=None, sim_path=None):\n",
    "        self.model = emb_model\n",
    "        self.words = []\n",
    "        self.sim_values = []\n",
    "        if words_path and sim_path: \n",
    "            with open(words_path, \"r\") as f:\n",
    "                self.words = f.readlines()\n",
    "            with open(sim_path, \"r\") as f:\n",
    "                self.sim_values = f.readlines()\n",
    "        self.num_words = len(self.words)\n",
    "    \n",
    "    def embed_word(self, word):\n",
    "        \"\"\"Get the FastText embedding for a word.\"\"\"\n",
    "        return self.model.get_word_vector(word)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_distance(vec1, vec2):\n",
    "        \"\"\"Compute cosine distance between two vectors.\"\"\"\n",
    "        return 1 - np.dot(vec1, vec2) / ((np.linalg.norm(vec1) * np.linalg.norm(vec2)) + 1e-8) #numerical stability\n",
    "    \n",
    "    @lru_cache(maxsize=1024)\n",
    "    def _word_cosine_distance(self, word1, word2):\n",
    "        word1_emb = self.embed_word(word1)\n",
    "        word2_emb = self.embed_word(word2)\n",
    "        return round(self.cosine_distance(word1_emb, word2_emb), 6)\n",
    "    \n",
    "    def c_word_cosine_distance(self, word1, word2):\n",
    "        # return random.randint(1, 10)/10\n",
    "        try:\n",
    "            w1_index = self.words.index(word1)\n",
    "            w2_index = self.words.index(word2)\n",
    "            cache_index = w1_index * self.num_words + w2_index\n",
    "            return self.sim_values[cache_index]\n",
    "        except ValueError:\n",
    "            return self._word_cosine_distance(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_data(words_path=SIM_WORDS_PATH, sim_path=SIM_VALUES_PATH):\n",
    "    \"\"\"Load word data and similarity values.\"\"\"\n",
    "    words = []\n",
    "    sim_values = []\n",
    "    if words_path and sim_path:\n",
    "        with open(words_path, \"r\") as f:\n",
    "            words = [x.strip() for x in f.readlines()]\n",
    "        with open(sim_path, \"r\") as f:\n",
    "            sim_values = [float(x) for x in f.readlines()]\n",
    "    return words, sim_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__model = en_model\n",
    "__words, __sim_values = load_word_data(SIM_WORDS_PATH, SIM_VALUES_PATH)\n",
    "__num_words = len(__words)\n",
    "__word2idx = {word: idx for word, idx in zip(__words, range(len(__words)))}\n",
    "\n",
    "__hits = 0\n",
    "__misses = 0\n",
    "\n",
    "def embed_word(word):\n",
    "    \"\"\"Get the FastText embedding for a word.\"\"\"\n",
    "    return __model.get_word_vector(word)\n",
    "\n",
    "def cosine_distance(vec1, vec2):\n",
    "    \"\"\"Compute cosine distance between two vectors.\"\"\"\n",
    "    return 1 - np.dot(vec1, vec2) / ((np.linalg.norm(vec1) * np.linalg.norm(vec2)) + 1e-8)  # numerical stability\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def word_cosine_distance(word1, word2):\n",
    "    \"\"\"Compute cosine distance between two words.\"\"\"\n",
    "    word1_emb = embed_word(word1)\n",
    "    word2_emb = embed_word(word2)\n",
    "    return cosine_distance(word1_emb, word2_emb)\n",
    "    # return int(1000 * cosine_distance(word1_emb, word2_emb))\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_stem(word):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "@lru_cache(maxsize=2048)\n",
    "def cached_word_cosine_distance(word1, word2):\n",
    "    # return 0\n",
    "    \"\"\"Compute cached cosine distance between two words.\"\"\"\n",
    "    global __hits, __misses\n",
    "    w1_index = __word2idx.get(word1, None)\n",
    "    w2_index = __word2idx.get(word2, None)\n",
    "    if w1_index and w2_index:\n",
    "        __hits += 1\n",
    "        cache_index = w1_index * __num_words + w2_index\n",
    "        # return int(1000 * __sim_values[cache_index])\n",
    "        return __sim_values[cache_index]\n",
    "\n",
    "    else:\n",
    "        __misses += 1\n",
    "        # return 0\n",
    "        return word_cosine_distance(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45927729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(__words) * len(__words)\n",
    "len(__sim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes stop words and punctuation from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Get the stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    \n",
    "    # Filter out stop words and punctuation\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word not in punctuation]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def read_file_from_zip(zip_path, file_name):\n",
    "    \"\"\"\n",
    "    Reads the content of a specific file from a zipped folder without extracting the entire folder.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to the zip file.\n",
    "        file_name (str): Name of the file to read within the zip.\n",
    "\n",
    "    Returns:\n",
    "        str: Content of the file as a string.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(file_name) as file:\n",
    "            return file.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_KNOWLEDGE_STORE = \"baseline/AVeriTeC/data_store/knowledge_store/dev_knowledge_store.zip\"\n",
    "TRAIN_KNOWLEDGE_STORE_999 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/train/train_0_999.zip\"\n",
    "TRAIN_KNOWLEDGE_STORE_1999 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/train/train_1000_1999.zip\"\n",
    "TRAIN_KNOWLEDGE_STORE_3067 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/train/train_2000_3067.zip\"\n",
    "TEST_KNOWLEDGE_STORE_499 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/test_updated/output_test_0_499.zip\"\n",
    "TEST_KNOWLEDGE_STORE_999 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/test_updated/output_test_500_999.zip\"\n",
    "TEST_KNOWLEDGE_STORE_1499 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/test_updated/output_test_1000_1499.zip\"\n",
    "TEST_KNOWLEDGE_STORE_1999 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/test_updated/output_test_1500_1999.zip\"\n",
    "TEST_KNOWLEDGE_STORE_2214 = \"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data_store/knowledge_store/test_updated/output_test_2000_2214.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knowledge_store_for_claim(claim_id, div=\"train\"):\n",
    "    references = []\n",
    "    try:\n",
    "        if div == \"train\":\n",
    "            if claim_id <= 999:\n",
    "                train_path = TRAIN_KNOWLEDGE_STORE_999\n",
    "            elif claim_id <= 1999:\n",
    "                train_path = TRAIN_KNOWLEDGE_STORE_1999\n",
    "            else:\n",
    "                train_path = TRAIN_KNOWLEDGE_STORE_3067\n",
    "            claim_file = read_file_from_zip(train_path, f\"{claim_id}.json\")\n",
    "        elif div == \"val\":\n",
    "            claim_file = read_file_from_zip(\"baseline/AVeriTeC/data_store/knowledge_store/dev_knowledge_store.zip\", f\"output_dev/{claim_id}.json\")\n",
    "        elif div == \"test\":\n",
    "            if claim_id <= 499:\n",
    "                test_path = TEST_KNOWLEDGE_STORE_499\n",
    "            elif claim_id <= 999:\n",
    "                test_path = TEST_KNOWLEDGE_STORE_999\n",
    "            elif claim_id <= 1499:\n",
    "                test_path = TEST_KNOWLEDGE_STORE_1499\n",
    "            elif claim_id <= 1999:\n",
    "                test_path = TEST_KNOWLEDGE_STORE_1999\n",
    "            else:\n",
    "                test_path = TEST_KNOWLEDGE_STORE_2214\n",
    "            claim_file = read_file_from_zip(test_path, f\"{claim_id}.json\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    for line in claim_file.splitlines():\n",
    "        try:\n",
    "            this_ref = json.loads(line)\n",
    "            references.append(this_ref)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_matching(query_embeddings, text_embeddings):\n",
    "    \"\"\"Find an optimal matching between query words and text words using the Hungarian algorithm.\"\"\"\n",
    "    cost_matrix = np.zeros((len(query_embeddings), len(text_embeddings)))\n",
    "    \n",
    "    for i, q_emb in enumerate(query_embeddings):\n",
    "        for j, t_emb in enumerate(text_embeddings):\n",
    "            cost_matrix[i, j] = cosine_distance(q_emb, t_emb)\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    total_score = -cost_matrix[row_ind, col_ind].sum()\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "\n",
    "cost_matrix = None #avoid having to assign memory with each call. Will resize cost matrix when shape changes\n",
    "def word_optimal_matching(query_words, text_words):\n",
    "    # cost_matrix = np.zeros((len(query_words), len(text_words)))\n",
    "    # return 0.1\n",
    "    global cost_matrix\n",
    "    shape = (len(query_words), len(text_words))\n",
    "    if cost_matrix is None or cost_matrix.shape != shape:\n",
    "        cost_matrix = np.zeros(shape)\n",
    "    else:\n",
    "        cost_matrix[:] = 1\n",
    "    for i, word1 in enumerate(query_words):\n",
    "        for j, word2 in enumerate(text_words):\n",
    "            dist = cached_word_cosine_distance(word1, word2)\n",
    "            # if dist > 0.7:\n",
    "            #     dist = 1\n",
    "            cost_matrix[i, j] = dist\n",
    "            \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    total_score = -cost_matrix[row_ind, col_ind].sum()\n",
    "    lev_score = Levenshtein.ratio(col_ind, sorted(col_ind))\n",
    "    match_width = max(col_ind) - min(col_ind)\n",
    "    \n",
    "    \n",
    "    return total_score#, lev_score, match_width\n",
    "\n",
    "def find_top_n_matches(query_text, target_text, patch_size=50, overlap=25, top_n=5, ret_string=False):\n",
    "    \"\"\"Find the top N scoring spans in the target text using a sliding window without redundant embeddings.\"\"\"\n",
    "    # target_words = [get_stem(word) for word in target_text.split()]\n",
    "    # query_words = [get_stem(word) for word in query_text.split()]\n",
    "    target_words = [word for word in target_text.split()]\n",
    "    query_words = [word for word in query_text.split()]\n",
    "    heap = []    \n",
    "    for start in range(0, max(1, len(target_words) - patch_size + 1), patch_size - overlap):\n",
    "        end = start + patch_size\n",
    "        curr_target_words = target_words[start:end]\n",
    "        score = word_optimal_matching(query_words, curr_target_words)\n",
    "        heapq.heappush(heap, (score, start, end))\n",
    "        if len(heap) > top_n:\n",
    "            heapq.heappop(heap)\n",
    "    if not ret_string: \n",
    "        return sorted(heap, reverse=True)\n",
    "    else:\n",
    "        top_matching = sorted(heap, reverse=True)\n",
    "        str_list = [\" \".join(target_text.split()[x[1]: x[2]]) for x in top_matching]\n",
    "        return [(score, span) for (score, _, _), span in zip(top_matching, str_list)]\n",
    "        \n",
    "        \n",
    "        # str_list = [\" \".join(query_words[x[-2]: x[-1]]) for x in top_matching]\n",
    "        # return [(str_score[0], str_val) for str_score, str_val in zip(top_matching, str_list)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tasks = None\n",
    "with open(\"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data/dev.json\") as f:\n",
    "    dev_tasks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claim_by_id(claim_list, claim_id):\n",
    "    filtered = claim_list[claim_id:claim_id+1]\n",
    "    return filtered[0] if filtered else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_text_from_claim_doc(claim_doc, span): \n",
    "    span = span[-2:]\n",
    "    claim_text = \" \".join(claim_doc.get(\"url2text\")).split()\n",
    "    return \" \".join(claim_text[span[0]: span[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_claim_doc(claim, claim_doc_dict, patch_size):\n",
    "    claim_text = \" \".join(claim_doc_dict.get(\"url2text\")).lower()[:1500]\n",
    "    top_matches = find_top_n_matches(claim, claim_text, patch_size=patch_size, overlap=0)\n",
    "    # claim_doc_dict[\"most_rel\"] =[]\n",
    "    # for i, match in enumerate(top_matches):\n",
    "    #     # match_text = get_span_text_from_claim_doc(claim_doc_dict, match)\n",
    "    #     claim_doc_dict[\"most_rel\"].append(match)\n",
    "    return claim_doc_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim_id = 4\n",
    "# claim = get_claim_by_id(dev_tasks, claim_id)\n",
    "# pprint(claim.get(\"label\"))\n",
    "# claim = claim.get(\"claim\")\n",
    "# claim_knowledge = get_knowledge_store_for_claim(claim_id)\n",
    "# print(len(claim_knowledge))\n",
    "# claim_knowledge = filter_claim_doc(claim, claim_knowledge[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_claim(claim_list, claim_id):\n",
    "    claim_id = claim_id\n",
    "    claim = get_claim_by_id(claim_list, claim_id)\n",
    "    claim_text = claim.get(\"claim\", \"\").lower()\n",
    "    patch_size = 96\n",
    "    claim_docs = get_knowledge_store_for_claim(claim_id)\n",
    "    claim_docs = [\n",
    "        filter_claim_doc(claim_text, doc, patch_size) for doc in claim_docs[:]\n",
    "    ]\n",
    "    return claim_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls: 0\n",
      "hits: 0, 0.00%\n",
      "misses: 0, 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"calls: {__hits + __misses}\")\n",
    "print(f\"hits: {__hits}, {(__hits/(__hits+__misses+1)):.2f}%\")\n",
    "print(f\"misses: {__misses}, {(__misses/(__hits+__misses+1)):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unterminated string starting at: line 1 column 29355 (char 29354)\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Execution time: 7.05 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "g = process_claim(dev_tasks, 5)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match score: -1.3169, Span: This is a robust graph matching algorithm for string search. We apply it to find patterns in text efficiently.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "target_text = \"This is a robust graph matching algorithm for string search. We apply it to find patterns in text efficiently.\"\n",
    "query_text = \"graph matching algorithm in bipartite graphs\"\n",
    "\n",
    "top_matches = find_top_n_matches(query_text, target_text)\n",
    "for score, start, end in top_matches:\n",
    "    print(f\"Match score: {score:.4f}, Span: {' '.join(target_text.split()[start:end])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for generating similarity_data \n",
    "\"\"\"\n",
    "\n",
    "N = 10000\n",
    "words = pd.read_csv(\"unigram_freq.csv\", dtype={\"word\": 'object'}, keep_default_na=False, na_values=[])[\"word\"]\n",
    "words = [x.lower() for x in words]\n",
    "words = words[:N]\n",
    "words = [stemmer.stem(word) for word in words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "similarity_index = [-1] * (len(words) * len(words))\n",
    "for idx, word in enumerate(words):\n",
    "    for idx2, word2 in enumerate(words):\n",
    "        similarity_index[idx * len(words) + idx2] = word_cosine_distance(word, word2)\n",
    "\n",
    "with open(\"similarity_data/sim.values.txt\", \"w\") as f:\n",
    "    for sim in similarity_index:\n",
    "        f.write(f\"{sim:.2f}\\n\")\n",
    "\n",
    "with open(\"similarity_data/sim.words.txt\", \"w\") as f: \n",
    "    for word in words:\n",
    "        f.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_index = None\n",
    "# with open(\"similarity_index.txt\", \"r\") as f:\n",
    "#     similarity_index = [float(x) for x in f.readlines()]\n",
    "\n",
    "# similarity_dict = {}\n",
    "# for idx, word in enumerate(words):\n",
    "#     for idx2, word2 in enumerate(words):\n",
    "#         similarity_dict[f\"{word}#{word2}\"] = similarity_index[idx * len(words) + idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def read_docx(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a .docx file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .docx file.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the .docx file as a single string.\n",
    "    \"\"\"\n",
    "    doc = Document(file_path)\n",
    "    content = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text.strip(): content.append(paragraph.text)\n",
    "    return '\\n'.join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZOL = \"/Users/tomi_owolabi/projects/starting_afresh/Sandoz_Concordia_chatbot/product_monographs/Zoledronic Acid - Z PMe 20170721.docx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zol_text = read_docx(ZOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_strings = [\"How does zoledronic acid work in the body?\",\n",
    "# \"What is the pharmacological mechanism behind zoledronic acid?\",\n",
    "# \"By what mechanism does zoledronic acid exert its effects?\",\n",
    "# \"What is the mode of action of zoledronic acid?\",\n",
    "# \"How does zoledronic acid produce its therapeutic effects?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(np.float64(-0.46955166902160644),\n",
      "  'acid is contraindicated in breast-feeding women (see CONTRAINDICATIONS). There is no clinical experience with '\n",
      "  'zoledronic acid in lactating women and it is not known whether zoledronic acid passes into breast milk. A study in '\n",
      "  'lactating rats has shown that another bisphosphonate, pamidronate, passes into the milk. Mothers treated with '\n",
      "  'zoledronic acid should therefore not breast feed their infants. Fertility The fertility was decreased in rats dosed '\n",
      "  'subcutaneously with 0.01 mg/kg/day of zoledronic acid, with systemic exposures of 0.12 times the human systemic '\n",
      "  'exposure following an intravenous dose of 4 mg (based on AUC). The effects observed included an increase in '\n",
      "  'pre-implantation losses and a decrease in the number of implantations and live foetuses. There are no data '\n",
      "  'available in humans.'),\n",
      " (np.float64(-0.5317228898010253),\n",
      "  'acid is administered in conjunction with drugs that are potentially nephrotoxic (e.g. aminoglycosides, other '\n",
      "  'antineoplastic agents, ASA, NSAIDs), or that can significantly impact renal function (e.g. diuretics, ACE '\n",
      "  'inhibitors, leading to dehydration). Caution is advised when zoledronic acid is administered with anti-angiogenic '\n",
      "  'drugs, as the incidence of ONJ is increased when these drugs are used concomitantly (see Osteonecrosis of the Jaw, '\n",
      "  'DRUG INTERACTIONS, Drug-Drug Interactions). Caution is advised when zoledronic acid is administered with loop '\n",
      "  'diuretics (particularly in patients treated for TIH), with aminoglycosides, or with calcitonin, since there may be '\n",
      "  'an additive effect on the risk of developing hypocalcemia. Zoledronic acid should be used with extreme caution in '\n",
      "  'conjunction with other antineoplastic agents that are known to produce renal'),\n",
      " (np.float64(-0.5706532463035583),\n",
      "  'presence of normal serum glucose, phosphate wasting, among other clinical features), treatment with Zoledronic Acid '\n",
      "  '- Z should be discontinued and appropriate treatment should be instated. Zoledronic acid should be used with '\n",
      "  'extreme caution in conjunction with other antineoplastic agents that are either known to produce renal impairment '\n",
      "  '(it is advised that renal function be monitored); or where the dose depends upon renal function (for example '\n",
      "  'platinum-containing agents). Respiratory Patients with Asthma While not observed in clinical trials with zoledronic '\n",
      "  'acid, administration of other bisphosphonates has been associated with bronchoconstriction in acetylsalicylic acid '\n",
      "  '(ASA)sensitive asthmatic patients. Zoledronic acid should be used with caution in patients with aspirinsensitive '\n",
      "  'asthma. Special Populations Renal Impairment Zoledronic acid is excreted exclusively via the kidney'),\n",
      " (np.float64(-0.5706532463035583),\n",
      "  'zoledronic acid or other bisphosphonates, or any of the excipients in the formulation of Zoledronic Acid - Z (see '\n",
      "  'DOSAGE FORMS, COMPOSITION AND PACKAGING). Non-corrected hypocalcaemia at the time of infusion (see WARNINGS AND '\n",
      "  'PRECAUTIONS, Hypocalcaemia). Pregnancy and breastfeeding women (see WARNINGS AND PRECAUTIONS, Special Populations) '\n",
      "  'WARNINGS AND PRECAUTIONS General Drug Interactions Zoledronic Acid - Z contains the same active ingredient that is '\n",
      "  'contained in zoledronic acid 5 mg/100 mL. Patients being treated with Zoledronic Acid - Z should not be treated '\n",
      "  'with zoledronic acid 5 mg/100 mL concomitantly. Zoledronic acid should not be given together with other '\n",
      "  'bisphosphonates since the combined effects of these agents are unknown. Zoledronic acid is eliminated by renal '\n",
      "  'excretion. Caution is indicated when zoledronic'),\n",
      " (np.float64(-0.6164712175331115),\n",
      "  'medicine used to treat high blood pressure or oedema) or other calcium-lowering medicines, since the combination of '\n",
      "  'these with bisphosphonates may cause the calcium level in the blood to become too low. Examples of aminoglycosides '\n",
      "  'include gentamycin sulfate, tobramycin sulfate and streptomycin sulphate; examples of loop diuretics include '\n",
      "  'furosemide, torsemide and ethacrinic acid. It is also important to inform your doctor if you are taking any drugs '\n",
      "  'that can have an effect on the kidney, since combining these drugs with Zoledronic Acid - Z may cause kidney '\n",
      "  'function to deteriorate. Some examples of these drugs include aminoglycosides, acetylsalicylic acid (ASA), '\n",
      "  'nonsteroidal antiinflammatories (e.g. ibuprofen, diclofenac, celecoxib), diuretics (e.g. hydrochlorothiazide, '\n",
      "  'amiloride, spironolactone and indapamide) and Angiotensin-Converting Enzyme (ACE) inhibitors (e.g. enalapril,'),\n",
      " (np.float64(-0.6217381223640441),\n",
      "  'your blood) What the medicinal ingredient is: Zoledronic acid. What the important non medicinal ingredients are: '\n",
      "  'Mannitol and sodium citrate. What dosage forms it comes in: Zoledronic Acid - Z is available as a concentrate in '\n",
      "  'vials. Each vial of Zoledronic Acid - Z concentrate delivers 4 mg of zoledronic acid. It is available in cartons '\n",
      "  'containing 1 vial. WARNINGS AND PRECAUTIONS Serious Warnings and Precautions Serious side effects which have been '\n",
      "  'reported with the use of zoledronic acid include: osteonecrosis of the jaw (a severe bone disease that affects the '\n",
      "  'jaw) deterioration in renal function. Zoledronic Acid - Z is not recommended in patients with severe kidney '\n",
      "  'impairment. hypocalcaemia (low calcium levels in your blood) If you are being'),\n",
      " (np.float64(-0.6502933963737487),\n",
      "  'numbness), maxillofacial pain, “toothaches”, denture sore spots, loose teeth, exposed bone in the oral cavity, '\n",
      "  'impaired healing, recurrent or persistent soft tissue infection in the oral cavity, and marked oral odour. The '\n",
      "  'onset can be from months to years after commencing bisphosphonate therapy. Cancer patients should maintain good '\n",
      "  'oral hygiene. It is recommended that cancer patients be encouraged to have an oral examination of both hard and '\n",
      "  'soft tissues, with appropriate preventive dentistry performed prior to treatment with zoledronic acid. These oral '\n",
      "  'assessments are recommended to be continued at regularly scheduled intervals after zoledronic acid therapy is '\n",
      "  'initiated and during treatment with zoledronic acid (see Monitoring and Laboratory Tests). While receiving '\n",
      "  'zoledronic acid therapy, patients should immediately report any oral'),\n",
      " (np.float64(-0.6502933963737487),\n",
      "  'patients treated with zoledronic acid or with other bisphosphonates. Although no causal relationship has been '\n",
      "  'established, there is an association between bisphosphonate use and the development of ONJ. Post-marketing '\n",
      "  'experience suggests a greater frequency of reports of ONJ based on tumour type (advanced breast cancer, multiple '\n",
      "  'myeloma) and dental status (dental extractions, periodontal disease, and local trauma including poorly fitting '\n",
      "  'dentures); these are associated with a greater risk of developing ONJ. Cancer patients also receive other '\n",
      "  'treatments that may play a role in the development of ONJ, such as chemotherapy and glucocorticosteroids. Many '\n",
      "  'patients reporting ONJ had signs of local infection including osteomyelitis (see ADVERSE REACTIONS, Post-Market '\n",
      "  'Adverse Drug Reactions). Presentation of ONJ may include altered local sensation (hyperesthesia or'),\n",
      " (np.float64(-0.6511678561172485),\n",
      "  'failure (very rarely with fatal outcome), has been reported with the use of zoledronic acid. Have asthma and are '\n",
      "  'also allergic to acetylsalicylic acid (ASA). Had or have a heart problem. Cases of irregular heart beat (atrial '\n",
      "  'fibrillation) have been observed with the use of zoledronic acid. Have any dental problems or any dental procedures '\n",
      "  'planned in the future. Have pain, swelling or numbness of the jaw, a “heavy jaw feeling”, loosening of a tooth, or '\n",
      "  'any other symptoms in your mouth. Have sores in your mouth. This can lead to osteonecrosis of the jaw. Your doctor '\n",
      "  'may check if you: smoke have or have had tooth and/or gum disease have dentures that do not fit well have other '\n",
      "  'medical'),\n",
      " (np.float64(-0.6922692463035583),\n",
      "  'treated with Zoledronic Acid - Z, you should not be treated with another intravenous form of zoledronic acid (i.e. '\n",
      "  'zoledronic acid 5 mg/ 100 mL) or other bisphosphonates (e.g. alendronate, risedronate, clodronate, etidronate and '\n",
      "  'pamidronate) at the same time. Your doctor may request an oral examination (an examination of your mouth and teeth) '\n",
      "  'before you start treatment and while you are on treatment with Zoledronic Acid - Z. This may be required since some '\n",
      "  'patients have experienced serious side effects following dental procedures (such as tooth extraction) while on '\n",
      "  'zoledronic acid; as well, since patients with unhealed open wounds in the mouth, dental infections or periodontal '\n",
      "  'disease (disease affecting the surrounding tissues of a tooth) may be at increased risk')]\n"
     ]
    }
   ],
   "source": [
    "# query_text = \"what are the contraindications of zoledronic acid\"\n",
    "# t = find_top_n_matches(query_text, target_text=zol_text, ret_string=True, top_n=10, overlap=0, patch_size=120)\n",
    "# pprint(t, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.73509175)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cosine_distance(\"theater\", \"sing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sentences_for_claim(div=\"train\"):\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
