{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "import heapq\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import random\n",
    "\n",
    "# Load FastText embeddings\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English model\n",
    "en_model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x1075d4ca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.reduce_model(en_model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from functools import lru_cache\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "# import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tomi_owolabi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tomi_owolabi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_VALUES = \"similarity_data/sim.values.txt\"\n",
    "SIM_WORDS = \"similarity_data/sim.words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDistance():\n",
    "    def __init__(self, emb_model, words_path=None, sim_path=None):\n",
    "        self.model = emb_model\n",
    "        self.words = []\n",
    "        self.sim_values = []\n",
    "        if words_path and sim_path: \n",
    "            with open(words_path, \"r\") as f:\n",
    "                self.words = f.readlines()\n",
    "            with open(sim_path, \"r\") as f:\n",
    "                self.sim_values = f.readlines()\n",
    "        self.num_words = len(self.words)\n",
    "    \n",
    "    def embed_word(self, word):\n",
    "        \"\"\"Get the FastText embedding for a word.\"\"\"\n",
    "        return self.model.get_word_vector(word)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_distance(vec1, vec2):\n",
    "        \"\"\"Compute cosine distance between two vectors.\"\"\"\n",
    "        return 1 - np.dot(vec1, vec2) / ((np.linalg.norm(vec1) * np.linalg.norm(vec2)) + 1e-8) #numerical stability\n",
    "    \n",
    "    @lru_cache(maxsize=1024)\n",
    "    def _word_cosine_distance(self, word1, word2):\n",
    "        word1_emb = self.embed_word(word1)\n",
    "        word2_emb = self.embed_word(word2)\n",
    "        return round(self.cosine_distance(word1_emb, word2_emb), 6)\n",
    "    \n",
    "    def c_word_cosine_distance(self, word1, word2):\n",
    "        # return random.randint(1, 10)/10\n",
    "        try:\n",
    "            w1_index = self.words.index(word1)\n",
    "            w2_index = self.words.index(word2)\n",
    "            cache_index = w1_index * self.num_words + w2_index\n",
    "            return self.sim_values[cache_index]\n",
    "        except ValueError:\n",
    "            return self._word_cosine_distance(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_data(words_path=None, sim_path=None):\n",
    "    \"\"\"Load word data and similarity values.\"\"\"\n",
    "    words = []\n",
    "    sim_values = []\n",
    "    if words_path and sim_path:\n",
    "        with open(words_path, \"r\") as f:\n",
    "            words = [x.strip() for x in f.readlines()]\n",
    "        with open(sim_path, \"r\") as f:\n",
    "            sim_values = [float(x) for x in f.readlines()]\n",
    "    return words, sim_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__model = en_model\n",
    "__words, __sim_values = load_word_data(\"similarity_data/sim.words.txt\", \"similarity_data/sim.values.txt\")\n",
    "__num_words = len(__words)\n",
    "__word2idx = {word: idx for word, idx in zip(__words, range(len(__words)))}\n",
    "\n",
    "__hits = 0\n",
    "__misses = 0\n",
    "\n",
    "def embed_word(word):\n",
    "    \"\"\"Get the FastText embedding for a word.\"\"\"\n",
    "    return __model.get_word_vector(word)\n",
    "\n",
    "def cosine_distance(vec1, vec2):\n",
    "    \"\"\"Compute cosine distance between two vectors.\"\"\"\n",
    "    return 1 - np.dot(vec1, vec2) / ((np.linalg.norm(vec1) * np.linalg.norm(vec2)) + 1e-8)  # numerical stability\n",
    "\n",
    "@lru_cache(maxsize=1024)\n",
    "def word_cosine_distance(word1, word2):\n",
    "    \"\"\"Compute cosine distance between two words.\"\"\"\n",
    "    word1_emb = embed_word(word1)\n",
    "    word2_emb = embed_word(word2)\n",
    "    return cosine_distance(word1_emb, word2_emb)\n",
    "    # return int(1000 * cosine_distance(word1_emb, word2_emb))\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_stem(word):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "@lru_cache(maxsize=2048)\n",
    "def cached_word_cosine_distance(word1, word2):\n",
    "    # return 0\n",
    "    \"\"\"Compute cached cosine distance between two words.\"\"\"\n",
    "    global __hits, __misses\n",
    "    w1_index = __word2idx.get(word1, None)\n",
    "    w2_index = __word2idx.get(word2, None)\n",
    "    if w1_index and w2_index:\n",
    "        __hits += 1\n",
    "        cache_index = w1_index * __num_words + w2_index\n",
    "        # return int(1000 * __sim_values[cache_index])\n",
    "        return __sim_values[cache_index]\n",
    "\n",
    "    else:\n",
    "        __misses += 1\n",
    "        # return 0\n",
    "        return word_cosine_distance(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45927729"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(__words) * len(__words)\n",
    "len(__sim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Removes stop words and punctuation from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Get the stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "    \n",
    "    # Filter out stop words and punctuation\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words and word not in punctuation]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def read_file_from_zip(zip_path, file_name):\n",
    "    \"\"\"\n",
    "    Reads the content of a specific file from a zipped folder without extracting the entire folder.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to the zip file.\n",
    "        file_name (str): Name of the file to read within the zip.\n",
    "\n",
    "    Returns:\n",
    "        str: Content of the file as a string.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(file_name) as file:\n",
    "            return file.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knowledge_store_for_claim(claim_id):\n",
    "    references = []\n",
    "    try:\n",
    "        claim_file = read_file_from_zip(\"baseline/AVeriTeC/data_store/knowledge_store/dev_knowledge_store.zip\", f\"output_dev/{claim_id}.json\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    for line in claim_file.splitlines():\n",
    "        try:\n",
    "            this_ref = json.loads(line)\n",
    "            references.append(this_ref)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_matching(query_embeddings, text_embeddings):\n",
    "    \"\"\"Find an optimal matching between query words and text words using the Hungarian algorithm.\"\"\"\n",
    "    cost_matrix = np.zeros((len(query_embeddings), len(text_embeddings)))\n",
    "    \n",
    "    for i, q_emb in enumerate(query_embeddings):\n",
    "        for j, t_emb in enumerate(text_embeddings):\n",
    "            cost_matrix[i, j] = cosine_distance(q_emb, t_emb)\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    total_score = -cost_matrix[row_ind, col_ind].sum()\n",
    "    \n",
    "    return total_score\n",
    "\n",
    "\n",
    "cost_matrix = None #avoid having to assign memory with each call. Will resize cost matrix when shape changes\n",
    "def word_optimal_matching(query_words, text_words):\n",
    "    # cost_matrix = np.zeros((len(query_words), len(text_words)))\n",
    "    # return 0.1\n",
    "    global cost_matrix\n",
    "    shape = (len(query_words), len(text_words))\n",
    "    if cost_matrix is None or cost_matrix.shape != shape:\n",
    "        cost_matrix = np.zeros(shape)\n",
    "    else:\n",
    "        cost_matrix[:] = 1\n",
    "    for i, word1 in enumerate(query_words):\n",
    "        for j, word2 in enumerate(text_words):\n",
    "            cost_matrix[i, j] = cached_word_cosine_distance(word1, word2)\n",
    "            \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    total_score = -cost_matrix[row_ind, col_ind].sum()\n",
    "    # lev_score = Levenshtein.ratio(col_ind, sorted(col_ind))\n",
    "    return total_score\n",
    "\n",
    "def find_top_n_matches(query_text, target_text, patch_size=50, overlap=25, top_n=5):\n",
    "    \"\"\"Find the top N scoring spans in the target text using a sliding window without redundant embeddings.\"\"\"\n",
    "    target_words = [get_stem(word) for word in target_text.split()]\n",
    "    query_words = [get_stem(word) for word in query_text.split()]\n",
    "    heap = []    \n",
    "    for start in range(0, max(1, len(target_words) - patch_size + 1), patch_size - overlap):\n",
    "        end = start + patch_size\n",
    "        curr_target_words = target_words[start:end]\n",
    "        score = word_optimal_matching(query_words, curr_target_words)\n",
    "        heapq.heappush(heap, (score, start, end))\n",
    "        if len(heap) > top_n:\n",
    "            heapq.heappop(heap)\n",
    "    return sorted(heap, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tasks = None\n",
    "with open(\"/Users/tomi_owolabi/projects/cpsc601/baseline/AVeriTeC/data/dev.json\") as f:\n",
    "    dev_tasks = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claim_by_id(claim_list, claim_id):\n",
    "    filtered = claim_list[claim_id:claim_id+1]\n",
    "    return filtered[0] if filtered else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_text_from_claim_doc(claim_doc, span): \n",
    "    span = span[-2:]\n",
    "    claim_text = \" \".join(claim_doc.get(\"url2text\")).split()\n",
    "    return \" \".join(claim_text[span[0]: span[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_claim_doc(claim, claim_doc_dict, patch_size):\n",
    "    claim_text = \" \".join(claim_doc_dict.get(\"url2text\")).lower()[:3000]\n",
    "    top_matches = find_top_n_matches(claim, claim_text, patch_size=patch_size, overlap=0)\n",
    "    # claim_doc_dict[\"most_rel\"] =[]\n",
    "    # for i, match in enumerate(top_matches):\n",
    "    #     # match_text = get_span_text_from_claim_doc(claim_doc_dict, match)\n",
    "    #     claim_doc_dict[\"most_rel\"].append(match)\n",
    "    return claim_doc_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claim_id = 4\n",
    "# claim = get_claim_by_id(dev_tasks, claim_id)\n",
    "# pprint(claim.get(\"label\"))\n",
    "# claim = claim.get(\"claim\")\n",
    "# claim_knowledge = get_knowledge_store_for_claim(claim_id)\n",
    "# print(len(claim_knowledge))\n",
    "# claim_knowledge = filter_claim_doc(claim, claim_knowledge[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_claim(claim_list, claim_id):\n",
    "    claim_id = claim_id\n",
    "    claim = get_claim_by_id(claim_list, claim_id)\n",
    "    claim_text = claim.get(\"claim\", \"\").lower()\n",
    "    patch_size = 64\n",
    "    claim_docs = get_knowledge_store_for_claim(claim_id)\n",
    "    claim_docs = [\n",
    "        filter_claim_doc(claim_text, doc, patch_size) for doc in claim_docs[:]\n",
    "    ]\n",
    "    return claim_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls: 4906722\n",
      "hits: 1989473, 0.41%\n",
      "misses: 2917249, 0.59%\n"
     ]
    }
   ],
   "source": [
    "print(f\"calls: {__hits + __misses}\")\n",
    "print(f\"hits: {__hits}, {(__hits/(__hits+__misses+1)):.2f}%\")\n",
    "print(f\"misses: {__misses}, {(__misses/(__hits+__misses+1)):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(len(get_knowledge_store_for_claim(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unterminated string starting at: line 1 column 786449 (char 786448)\n",
      "Extra data: line 1 column 6 (char 5)\n",
      "Extra data: line 1 column 6 (char 5)\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Extra data: line 1 column 6 (char 5)\n",
      "Extra data: line 1 column 3 (char 2)\n",
      "Unterminated string starting at: line 1 column 786633 (char 786632)\n",
      "Expecting value: line 1 column 1 (char 0)\n",
      "Extra data: line 1 column 6 (char 5)\n",
      "Extra data: line 1 column 3 (char 2)\n",
      "Execution time: 22.78 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "g = process_claim(dev_tasks, 2)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match score: -1.0950, Span: This is a robust graph matching algorithm for string search. We apply it to find patterns in text efficiently.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "target_text = \"This is a robust graph matching algorithm for string search. We apply it to find patterns in text efficiently.\"\n",
    "query_text = \"graph matching algorithm in bipartite graphs\"\n",
    "\n",
    "top_matches = find_top_n_matches(query_text, target_text)\n",
    "for score, start, end in top_matches:\n",
    "    print(f\"Match score: {score:.4f}, Span: {' '.join(target_text.split()[start:end])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "words = pd.read_csv(\"unigram_freq.csv\", dtype={\"word\": 'object'}, keep_default_na=False, na_values=[])[\"word\"]\n",
    "words = [x.lower() for x in words]\n",
    "words = words[:N]\n",
    "words = [stemmer.stem(word) for word in words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "similarity_index = [-1] * (len(words) * len(words))\n",
    "for idx, word in enumerate(words):\n",
    "    for idx2, word2 in enumerate(words):\n",
    "        similarity_index[idx * len(words) + idx2] = word_cosine_distance(word, word2)\n",
    "\n",
    "with open(\"similarity_data/sim.values.txt\", \"w\") as f:\n",
    "    for sim in similarity_index:\n",
    "        f.write(f\"{sim:2f}\\n\")\n",
    "\n",
    "with open(\"similarity_data/sim.words.txt\", \"w\") as f: \n",
    "    for word in words:\n",
    "        f.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_index = None\n",
    "# with open(\"similarity_index.txt\", \"r\") as f:\n",
    "#     similarity_index = [float(x) for x in f.readlines()]\n",
    "\n",
    "# similarity_dict = {}\n",
    "# for idx, word in enumerate(words):\n",
    "#     for idx2, word2 in enumerate(words):\n",
    "#         similarity_dict[f\"{word}#{word2}\"] = similarity_index[idx * len(words) + idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'aberdeen',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'aborigin',\n",
       " 'abort',\n",
       " 'about',\n",
       " 'abov',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'absenc',\n",
       " 'absent',\n",
       " 'absolut',\n",
       " 'absorpt',\n",
       " 'abstract',\n",
       " 'abu',\n",
       " 'abus',\n",
       " 'ac',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'acc',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'accommod',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'accordingli',\n",
       " 'account',\n",
       " 'accredit',\n",
       " 'accur',\n",
       " 'accuraci',\n",
       " 'accus',\n",
       " 'acdbent',\n",
       " 'ace',\n",
       " 'acer',\n",
       " 'achiev',\n",
       " 'acid',\n",
       " 'acknowledg',\n",
       " 'acm',\n",
       " 'acn',\n",
       " 'acoust',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'acr',\n",
       " 'acrobat',\n",
       " 'across',\n",
       " 'acryl',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'acut',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adaptor',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adelaid',\n",
       " 'adequ',\n",
       " 'adida',\n",
       " 'adipex',\n",
       " 'adjac',\n",
       " 'adjust',\n",
       " 'admin',\n",
       " 'administ',\n",
       " 'administr',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'adob',\n",
       " 'adolesc',\n",
       " 'adopt',\n",
       " 'adrian',\n",
       " 'adsl',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adventur',\n",
       " 'advers',\n",
       " 'advert',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'advisori',\n",
       " 'advoc',\n",
       " 'advocaci',\n",
       " 'adwar',\n",
       " 'ae',\n",
       " 'aerial',\n",
       " 'aerospac',\n",
       " 'af',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affili',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'agricultur',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airfar',\n",
       " 'airlin',\n",
       " 'airplan',\n",
       " 'airport',\n",
       " 'aj',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'albani',\n",
       " 'albania',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'album',\n",
       " 'albuquerqu',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexand',\n",
       " 'alexandria',\n",
       " 'alfr',\n",
       " 'algebra',\n",
       " 'algeria',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'alic',\n",
       " 'alien',\n",
       " 'align',\n",
       " 'alik',\n",
       " 'aliv',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'alleg',\n",
       " 'allen',\n",
       " 'allergi',\n",
       " 'alli',\n",
       " 'allianc',\n",
       " 'alloc',\n",
       " 'allow',\n",
       " 'alloy',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alpin',\n",
       " 'alreadi',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'alto',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'alumni',\n",
       " 'alway',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amaz',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambien',\n",
       " 'ambient',\n",
       " 'amd',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ami',\n",
       " 'amino',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'ampland',\n",
       " 'amplifi',\n",
       " 'amsterdam',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anaheim',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analys',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'analyt',\n",
       " 'analyz',\n",
       " 'anatomi',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andal',\n",
       " 'anderson',\n",
       " 'andi',\n",
       " 'andorra',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'anger',\n",
       " 'angl',\n",
       " 'angola',\n",
       " 'angri',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annex',\n",
       " 'anni',\n",
       " 'anniversari',\n",
       " 'annot',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'anonym',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antarctica',\n",
       " 'antenna',\n",
       " 'anthoni',\n",
       " 'anthropolog',\n",
       " 'anti',\n",
       " 'antibodi',\n",
       " 'anticip',\n",
       " 'antigua',\n",
       " 'antiqu',\n",
       " 'antiviru',\n",
       " 'antonio',\n",
       " 'anxieti',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'aol',\n",
       " 'ap',\n",
       " 'apach',\n",
       " 'apart',\n",
       " 'api',\n",
       " 'apnic',\n",
       " 'apollo',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'apparatu',\n",
       " 'apparel',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appendix',\n",
       " 'appl',\n",
       " 'appli',\n",
       " 'applianc',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'apprais',\n",
       " 'appreci',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'approx',\n",
       " 'approxim',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquat',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arbitr',\n",
       " 'arbitrari',\n",
       " 'arbor',\n",
       " 'arc',\n",
       " 'arcad',\n",
       " 'arch',\n",
       " 'architect',\n",
       " 'architectur',\n",
       " 'archiv',\n",
       " 'arctic',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'arg',\n",
       " 'argentina',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'aris',\n",
       " 'arizona',\n",
       " 'arkansa',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armenia',\n",
       " 'armi',\n",
       " 'armor',\n",
       " 'armstrong',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arrang',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'arthriti',\n",
       " 'arthur',\n",
       " 'articl',\n",
       " 'artifici',\n",
       " 'artist',\n",
       " 'artwork',\n",
       " 'aruba',\n",
       " 'as',\n",
       " 'asbesto',\n",
       " 'ascii',\n",
       " 'ash',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asid',\n",
       " 'asin',\n",
       " 'ask',\n",
       " 'asn',\n",
       " 'asp',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'assess',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'asthma',\n",
       " 'astrolog',\n",
       " 'astronomi',\n",
       " 'asu',\n",
       " 'asylum',\n",
       " 'at',\n",
       " 'ata',\n",
       " 'ate',\n",
       " 'athen',\n",
       " 'athlet',\n",
       " 'ati',\n",
       " 'atla',\n",
       " 'atlant',\n",
       " 'atlanta',\n",
       " 'atm',\n",
       " 'atmospher',\n",
       " 'atom',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'au',\n",
       " 'auburn',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'aud',\n",
       " 'audi',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'auditor',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'aurora',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austria',\n",
       " 'authent',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'autom',\n",
       " 'automat',\n",
       " 'automobil',\n",
       " 'automot',\n",
       " 'autumn',\n",
       " 'av',\n",
       " 'avail',\n",
       " 'avatar',\n",
       " 'ave',\n",
       " 'avenu',\n",
       " 'averag',\n",
       " 'avg',\n",
       " 'avi',\n",
       " 'aviat',\n",
       " 'avoid',\n",
       " 'avon',\n",
       " 'aw',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'axi',\n",
       " 'aye',\n",
       " 'az',\n",
       " 'azerbaijan',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'bachelor',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backup',\n",
       " 'bacon',\n",
       " 'bacteri',\n",
       " 'bacteria',\n",
       " 'bad',\n",
       " 'badg',\n",
       " 'badli',\n",
       " 'bag',\n",
       " 'baghdad',\n",
       " 'bahama',\n",
       " 'bahrain',\n",
       " 'bailey',\n",
       " 'bake',\n",
       " 'baker',\n",
       " 'balanc',\n",
       " 'bald',\n",
       " 'bali',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'balloon',\n",
       " 'ballot',\n",
       " 'baltimor',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bandwidth',\n",
       " 'bang',\n",
       " 'bangbu',\n",
       " 'bangkok',\n",
       " 'bangladesh',\n",
       " 'bank',\n",
       " 'bankruptci',\n",
       " 'banner',\n",
       " 'baptist',\n",
       " 'bar',\n",
       " 'barbado',\n",
       " 'barbara',\n",
       " 'barbi',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'bargain',\n",
       " 'barn',\n",
       " 'barrel',\n",
       " 'barri',\n",
       " 'barrier',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'baselin',\n",
       " 'basement',\n",
       " 'basenam',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basin',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'bass',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'battlefield',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbw',\n",
       " 'bc',\n",
       " 'bd',\n",
       " 'bdsm',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bead',\n",
       " 'beam',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beastal',\n",
       " 'beastial',\n",
       " 'beat',\n",
       " 'beatl',\n",
       " 'beauti',\n",
       " 'beaver',\n",
       " 'becam',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'bedford',\n",
       " 'bedroom',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'befor',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginn',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " 'beij',\n",
       " 'belaru',\n",
       " 'belfast',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'beliz',\n",
       " 'belkin',\n",
       " 'bell',\n",
       " 'belli',\n",
       " 'belong',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'bench',\n",
       " 'benchmark',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefici',\n",
       " 'benefit',\n",
       " 'benjamin',\n",
       " 'bennett',\n",
       " 'bent',\n",
       " 'benz',\n",
       " 'berkeley',\n",
       " 'berlin',\n",
       " 'bermuda',\n",
       " 'bernard',\n",
       " 'berri',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bestial',\n",
       " 'bestsel',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'beth',\n",
       " 'better',\n",
       " 'betti',\n",
       " 'between',\n",
       " 'beverag',\n",
       " 'beverli',\n",
       " 'beyond',\n",
       " 'bg',\n",
       " 'bhutan',\n",
       " 'bi',\n",
       " 'bia',\n",
       " 'bibl',\n",
       " 'biblic',\n",
       " 'bibliograph',\n",
       " 'bibliographi',\n",
       " 'bicycl',\n",
       " 'bid',\n",
       " 'bidder',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bikini',\n",
       " 'bill',\n",
       " 'billi',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'binari',\n",
       " 'bind',\n",
       " 'bingo',\n",
       " 'bio',\n",
       " 'biodivers',\n",
       " 'biographi',\n",
       " 'biol',\n",
       " 'biolog',\n",
       " 'biotechnolog',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bishop',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'biz',\n",
       " 'bizarr',\n",
       " 'bizrat',\n",
       " 'bk',\n",
       " 'bl',\n",
       " 'black',\n",
       " 'blackberri',\n",
       " 'blackjack',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blair',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'blink',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blogger',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'bloom',\n",
       " 'bloomberg',\n",
       " 'blow',\n",
       " 'blowjob',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'blvd',\n",
       " 'bm',\n",
       " 'bmw',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobbi',\n",
       " 'boc',\n",
       " 'bodi',\n",
       " 'bold',\n",
       " 'bolivia',\n",
       " 'bolt',\n",
       " 'bomb',\n",
       " 'bon',\n",
       " 'bond',\n",
       " 'bondag',\n",
       " 'bone',\n",
       " 'bonu',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'bookmark',\n",
       " 'bookstor',\n",
       " 'bool',\n",
       " 'boolean',\n",
       " 'boom',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'booth',\n",
       " 'booti',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'born',\n",
       " 'borough',\n",
       " 'bosnia',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'botswana',\n",
       " 'bottl',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'boulder',\n",
       " 'boulevard',\n",
       " 'bound',\n",
       " 'boundari',\n",
       " 'bouquet',\n",
       " 'boutiqu',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'bp',\n",
       " 'br',\n",
       " 'bra',\n",
       " 'bracelet',\n",
       " 'bracket',\n",
       " 'brad',\n",
       " 'bradford',\n",
       " 'bradley',\n",
       " 'brain',\n",
       " 'brake',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brandon',\n",
       " 'brass',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breed',\n",
       " 'brian',\n",
       " 'brick',\n",
       " 'bridal',\n",
       " 'bride',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'bright',\n",
       " 'brighton',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'brisban',\n",
       " 'bristol',\n",
       " 'britain',\n",
       " 'britannica',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'broad',\n",
       " 'broadband',\n",
       " 'broadcast',\n",
       " 'broader',\n",
       " 'broadway',\n",
       " 'brochur',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'bronz',\n",
       " 'brook',\n",
       " 'brooklyn',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brows',\n",
       " 'browser',\n",
       " 'bruce',\n",
       " 'brunei',\n",
       " 'brunett',\n",
       " 'brunswick',\n",
       " 'brush',\n",
       " 'brussel',\n",
       " 'brutal',\n",
       " 'bryan',\n",
       " 'bryant',\n",
       " 'bs',\n",
       " 'bt',\n",
       " 'bu',\n",
       " 'bubbl',\n",
       " 'buck',\n",
       " 'budapest',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'buf',\n",
       " 'bufe',\n",
       " 'buffalo',\n",
       " 'buffer',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'builder',\n",
       " 'built',\n",
       " 'bukkak',\n",
       " 'bulgaria',\n",
       " 'bulgarian',\n",
       " 'bulk',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bulletin',\n",
       " 'bumper',\n",
       " 'bunch',\n",
       " 'bundl',\n",
       " 'bunni',\n",
       " 'burden',\n",
       " 'bureau',\n",
       " 'buri',\n",
       " 'burk',\n",
       " 'burlington',\n",
       " 'burn',\n",
       " 'burner',\n",
       " 'burst',\n",
       " 'burton',\n",
       " 'buse',\n",
       " 'bush',\n",
       " 'busi',\n",
       " 'busti',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterfli',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buzz',\n",
       " 'bw',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'byte',\n",
       " 'c',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabinet',\n",
       " 'cabl',\n",
       " 'cach',\n",
       " 'cad',\n",
       " 'cadillac',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calcium',\n",
       " 'calcul',\n",
       " 'calendar',\n",
       " 'calgari',\n",
       " 'calibr',\n",
       " 'california',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'calvin',\n",
       " 'cam',\n",
       " 'cambodia',\n",
       " 'cambridg',\n",
       " 'camcord',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camera',\n",
       " 'cameron',\n",
       " 'cameroon',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'campbel',\n",
       " 'campu',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'canal',\n",
       " 'canberra',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candi',\n",
       " 'candid',\n",
       " 'candl',\n",
       " 'cannon',\n",
       " 'canon',\n",
       " 'cant',\n",
       " 'canva',\n",
       " 'canyon',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'capac',\n",
       " 'cape',\n",
       " 'capit',\n",
       " 'capitol',\n",
       " 'captain',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'carb',\n",
       " 'carbon',\n",
       " 'card',\n",
       " 'cardiac',\n",
       " 'cardiff',\n",
       " 'cardiovascular',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carey',\n",
       " 'cargo',\n",
       " 'caribbean',\n",
       " 'carl',\n",
       " 'carlo',\n",
       " 'carmen',\n",
       " 'carniv',\n",
       " 'carol',\n",
       " 'carolin',\n",
       " 'carolina',\n",
       " 'carpet',\n",
       " 'carri',\n",
       " 'carrier',\n",
       " 'carrol',\n",
       " 'cart',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'cartridg',\n",
       " 'casa',\n",
       " 'case',\n",
       " 'casey',\n",
       " 'cash',\n",
       " 'cashier',\n",
       " 'casino',\n",
       " 'casio',\n",
       " 'cassett',\n",
       " 'cast',\n",
       " 'castl',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catalog',\n",
       " 'catalogu',\n",
       " 'catalyst',\n",
       " 'catch',\n",
       " 'categori',\n",
       " 'cater',\n",
       " 'cathedr',\n",
       " 'catherin',\n",
       " 'cathol',\n",
       " 'cattl',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'caution',\n",
       " 'cave',\n",
       " 'cayman',\n",
       " 'cb',\n",
       " 'cc',\n",
       " 'ccd',\n",
       " 'cd',\n",
       " 'cdna',\n",
       " 'cdt',\n",
       " 'ce',\n",
       " 'cedar',\n",
       " 'ceil',\n",
       " 'celeb',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'cellular',\n",
       " 'celtic',\n",
       " 'cement',\n",
       " 'cemeteri',\n",
       " 'censu',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'ceo',\n",
       " 'ceram',\n",
       " 'ceremoni',\n",
       " 'certain',\n",
       " 'certainli',\n",
       " 'certif',\n",
       " 'certifi',\n",
       " 'cet',\n",
       " 'cf',\n",
       " 'cfr',\n",
       " 'cg',\n",
       " 'cgi',\n",
       " 'ch',\n",
       " ...]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.550554,\n",
       " 0.744979,\n",
       " 0.848233,\n",
       " 0.740294,\n",
       " 0.753646,\n",
       " 0.872898,\n",
       " 0.947873,\n",
       " 0.71445,\n",
       " 0.725884,\n",
       " 1.016495,\n",
       " 0.82227,\n",
       " 0.640478,\n",
       " 0.858973,\n",
       " 0.856821,\n",
       " 0.972242,\n",
       " 1.032808,\n",
       " 0.863104,\n",
       " 0.717235,\n",
       " 0.986695,\n",
       " 0.859122,\n",
       " 0.823554,\n",
       " 0.862805,\n",
       " 0.762871,\n",
       " 0.816648,\n",
       " 0.825239,\n",
       " 0.780274,\n",
       " 0.880491,\n",
       " 0.731825,\n",
       " 0.783766,\n",
       " 0.834516,\n",
       " 0.94247,\n",
       " 0.843915,\n",
       " 0.835194,\n",
       " 0.8246,\n",
       " 0.879746,\n",
       " 1.049659,\n",
       " 0.762097,\n",
       " 0.837168,\n",
       " 0.938754,\n",
       " 0.980094,\n",
       " 0.774667,\n",
       " 0.889839,\n",
       " 0.74154,\n",
       " 0.829268,\n",
       " 0.841474,\n",
       " 0.924383,\n",
       " 0.816601,\n",
       " 0.863822,\n",
       " 0.773569,\n",
       " 1.15509,\n",
       " 0.757455,\n",
       " 1.07421,\n",
       " 0.813577,\n",
       " 0.836149,\n",
       " 0.840244,\n",
       " 0.916852,\n",
       " 0.784471,\n",
       " 0.827206,\n",
       " 0.89532,\n",
       " 0.841351,\n",
       " 0.840952,\n",
       " 0.88747,\n",
       " 0.72109,\n",
       " 0.88421,\n",
       " 0.785367,\n",
       " 0.722857,\n",
       " 0.85984,\n",
       " 0.844101,\n",
       " 0.857286,\n",
       " 0.636309,\n",
       " 0.863392,\n",
       " 0.82921,\n",
       " 0.761535,\n",
       " 0.915212,\n",
       " 0.994642,\n",
       " 1.009633,\n",
       " 0.933755,\n",
       " 1.159539,\n",
       " 0.769882,\n",
       " 0.989255,\n",
       " 0.763435,\n",
       " 0.799286,\n",
       " 0.925864,\n",
       " 0.751202,\n",
       " 1.002029,\n",
       " 1.071777,\n",
       " 0.789124,\n",
       " 0.919965,\n",
       " 0.837641,\n",
       " 0.791425,\n",
       " 0.869882,\n",
       " 0.827207,\n",
       " 0.877149,\n",
       " 1.089392,\n",
       " 0.900856,\n",
       " 0.850743,\n",
       " 0.838553,\n",
       " 0.83358,\n",
       " 0.839113,\n",
       " 1.065424,\n",
       " 0.974467,\n",
       " 1.064268,\n",
       " 1.152708,\n",
       " 0.572511,\n",
       " 0.867424,\n",
       " 1.070181,\n",
       " 0.722807,\n",
       " 0.766159,\n",
       " 0.829023,\n",
       " 0.867206,\n",
       " 0.815892,\n",
       " 0.870928,\n",
       " 0.847578,\n",
       " 0.963,\n",
       " 0.912863,\n",
       " 0.725768,\n",
       " 0.83612,\n",
       " 0.905324,\n",
       " 0.733487,\n",
       " 0.741718,\n",
       " 0.820094,\n",
       " 0.791083,\n",
       " 0.828582,\n",
       " 0.88368,\n",
       " 0.842244,\n",
       " 1.035641,\n",
       " 0.874356,\n",
       " 0.883393,\n",
       " 0.923326,\n",
       " 0.810252,\n",
       " 0.948493,\n",
       " 0.633042,\n",
       " 0.845117,\n",
       " 0.699954,\n",
       " 0.896782,\n",
       " 0.755286,\n",
       " 0.916216,\n",
       " 0.948636,\n",
       " 1.149097,\n",
       " 1.044462,\n",
       " 1.076679,\n",
       " 0.912925,\n",
       " 0.778735,\n",
       " 0.714637,\n",
       " 0.848788,\n",
       " 0.773727,\n",
       " 0.832872,\n",
       " 0.924273,\n",
       " 0.890831,\n",
       " 0.86013,\n",
       " 0.893364,\n",
       " 0.870151,\n",
       " 0.97342,\n",
       " 0.896682,\n",
       " 0.882028,\n",
       " 0.838857,\n",
       " 0.964859,\n",
       " 0.917995,\n",
       " 0.906992,\n",
       " 0.908153,\n",
       " 1.042424,\n",
       " 0.972666,\n",
       " 0.906038,\n",
       " 0.852399,\n",
       " 0.898042,\n",
       " 0.888583,\n",
       " 0.869712,\n",
       " 0.826814,\n",
       " 0.961051,\n",
       " 0.871153,\n",
       " 0.790488,\n",
       " 0.900478,\n",
       " 0.819533,\n",
       " 0.778188,\n",
       " 0.845446,\n",
       " 0.876065,\n",
       " 0.83888,\n",
       " 0.922674,\n",
       " 1.084791,\n",
       " 0.907234,\n",
       " 1.034388,\n",
       " 0.845294,\n",
       " 0.721771,\n",
       " 0.905418,\n",
       " 0.620351,\n",
       " 0.749044,\n",
       " 0.7151,\n",
       " 0.809132,\n",
       " 0.808213,\n",
       " 0.807726,\n",
       " 0.923166,\n",
       " 0.954912,\n",
       " 0.716751,\n",
       " 0.807098,\n",
       " 0.744802,\n",
       " 0.867364,\n",
       " 0.736651,\n",
       " 0.873755,\n",
       " 0.921161,\n",
       " 0.895119,\n",
       " 0.99072,\n",
       " 0.787529,\n",
       " 0.587556,\n",
       " 0.904062,\n",
       " 0.836043,\n",
       " 0.718562,\n",
       " 0.911607,\n",
       " 0.862368,\n",
       " 0.90246,\n",
       " 0.941307,\n",
       " 0.896676,\n",
       " 0.918357,\n",
       " 0.849351,\n",
       " 0.814551,\n",
       " 0.992691,\n",
       " 0.905413,\n",
       " 0.804364,\n",
       " 0.93333,\n",
       " 0.825402,\n",
       " 0.845903,\n",
       " 0.74317,\n",
       " 0.854074,\n",
       " 0.802537,\n",
       " 0.828903,\n",
       " 0.96375,\n",
       " 0.436895,\n",
       " 0.807675,\n",
       " 0.976357,\n",
       " 0.854992,\n",
       " 0.890599,\n",
       " 0.939524,\n",
       " 0.922571,\n",
       " 0.893973,\n",
       " 0.998476,\n",
       " 0.783707,\n",
       " 1.056496,\n",
       " 0.858984,\n",
       " 0.850342,\n",
       " 0.72148,\n",
       " 0.860399,\n",
       " 0.871095,\n",
       " 0.95183,\n",
       " 0.973856,\n",
       " 0.90277,\n",
       " 0.929784,\n",
       " 0.883605,\n",
       " 0.940419,\n",
       " 0.87794,\n",
       " 0.916362,\n",
       " 0.927089,\n",
       " 1.1349,\n",
       " 0.804897,\n",
       " 0.89593,\n",
       " 0.804094,\n",
       " 0.896842,\n",
       " 0.911492,\n",
       " 0.905884,\n",
       " 1.033379,\n",
       " 0.856834,\n",
       " 0.93702,\n",
       " 0.862321,\n",
       " 0.714251,\n",
       " 0.892468,\n",
       " 0.548923,\n",
       " 0.810748,\n",
       " 0.798228,\n",
       " 1.002729,\n",
       " 0.895178,\n",
       " 0.990285,\n",
       " 1.098917,\n",
       " 0.754552,\n",
       " 0.957455,\n",
       " 1.030366,\n",
       " 0.890456,\n",
       " 1.105726,\n",
       " 1.001929,\n",
       " 0.931041,\n",
       " 1.014562,\n",
       " 0.983399,\n",
       " 0.816405,\n",
       " 0.874982,\n",
       " 0.659848,\n",
       " 0.965334,\n",
       " 0.775016,\n",
       " 0.811915,\n",
       " 0.919853,\n",
       " 0.703605,\n",
       " 1.03631,\n",
       " 0.868031,\n",
       " 0.887713,\n",
       " 1.02897,\n",
       " 0.918296,\n",
       " 0.839797,\n",
       " 0.741368,\n",
       " 1.17347,\n",
       " 0.890024,\n",
       " 0.795796,\n",
       " 0.820089,\n",
       " 0.937472,\n",
       " 0.825829,\n",
       " 0.820228,\n",
       " 0.863942,\n",
       " 0.772354,\n",
       " 0.704932,\n",
       " 1.035609,\n",
       " 0.850428,\n",
       " 0.77986,\n",
       " 0.81939,\n",
       " 0.772932,\n",
       " 0.631395,\n",
       " 0.731858,\n",
       " 0.9135,\n",
       " 0.907896,\n",
       " 0.828218,\n",
       " 0.822739,\n",
       " 0.902721,\n",
       " 1.227093,\n",
       " 0.699851,\n",
       " 0.879997,\n",
       " 0.969544,\n",
       " 1.126941,\n",
       " 0.976713,\n",
       " 0.814943,\n",
       " 0.823684,\n",
       " 1.05452,\n",
       " 0.880782,\n",
       " 0.832988,\n",
       " 0.863837,\n",
       " 0.872477,\n",
       " 0.952577,\n",
       " 0.770772,\n",
       " 0.853896,\n",
       " 0.887434,\n",
       " 0.751873,\n",
       " 0.975906,\n",
       " 0.767535,\n",
       " 0.790344,\n",
       " 0.899086,\n",
       " 0.886623,\n",
       " 0.996644,\n",
       " 0.884744,\n",
       " 0.839714,\n",
       " 0.925057,\n",
       " 0.938389,\n",
       " 0.916682,\n",
       " 0.890936,\n",
       " 0.817047,\n",
       " 0.809541,\n",
       " 0.948213,\n",
       " 0.755371,\n",
       " 0.894682,\n",
       " 0.845906,\n",
       " 0.840616,\n",
       " 0.850583,\n",
       " 1.055991,\n",
       " 0.883109,\n",
       " 0.83463,\n",
       " 1.050831,\n",
       " 0.852416,\n",
       " 0.925559,\n",
       " 0.932223,\n",
       " 0.383938,\n",
       " 1.04127,\n",
       " 0.953826,\n",
       " 0.939163,\n",
       " 0.948386,\n",
       " 0.968951,\n",
       " 0.846807,\n",
       " 1.012195,\n",
       " 0.802851,\n",
       " 0.775028,\n",
       " 0.670793,\n",
       " 0.776416,\n",
       " 0.782292,\n",
       " 0.869149,\n",
       " 0.83087,\n",
       " 0.858798,\n",
       " 0.740442,\n",
       " 0.854429,\n",
       " 0.649193,\n",
       " 0.871577,\n",
       " 0.759846,\n",
       " 0.73944,\n",
       " 0.908717,\n",
       " 0.742647,\n",
       " 0.899226,\n",
       " 1.00646,\n",
       " 1.021546,\n",
       " 0.766137,\n",
       " 0.892824,\n",
       " 0.48899,\n",
       " 0.620541,\n",
       " 0.860906,\n",
       " 0.829114,\n",
       " 0.803902,\n",
       " 0.795548,\n",
       " 0.819605,\n",
       " 1.049161,\n",
       " 0.942622,\n",
       " 0.911679,\n",
       " 0.900147,\n",
       " 0.810393,\n",
       " 0.76647,\n",
       " 0.85211,\n",
       " 0.701813,\n",
       " 0.820618,\n",
       " 0.933627,\n",
       " 0.894962,\n",
       " 0.839839,\n",
       " 0.751075,\n",
       " 0.842403,\n",
       " 0.561061,\n",
       " 0.907149,\n",
       " 0.933259,\n",
       " 0.882372,\n",
       " 0.81472,\n",
       " 0.834977,\n",
       " 0.862196,\n",
       " 0.899723,\n",
       " 0.908348,\n",
       " 0.936876,\n",
       " 0.909442,\n",
       " 0.913773,\n",
       " 0.976735,\n",
       " 0.972229,\n",
       " 0.930061,\n",
       " 0.874435,\n",
       " 0.975769,\n",
       " 0.823098,\n",
       " 0.866314,\n",
       " 0.883304,\n",
       " 0.967495,\n",
       " 0.883247,\n",
       " 0.916994,\n",
       " 1.002192,\n",
       " 0.880668,\n",
       " 0.715563,\n",
       " 0.909546,\n",
       " 0.881173,\n",
       " 0.877141,\n",
       " 1.062342,\n",
       " 0.769364,\n",
       " 0.715774,\n",
       " 0.825185,\n",
       " 1.076815,\n",
       " 0.771313,\n",
       " 0.885583,\n",
       " 0.64752,\n",
       " 0.754126,\n",
       " 0.837872,\n",
       " 0.845479,\n",
       " 0.896097,\n",
       " 0.801438,\n",
       " 0.84397,\n",
       " 0.785435,\n",
       " 0.880372,\n",
       " 0.716003,\n",
       " 0.645064,\n",
       " 0.805464,\n",
       " 0.776286,\n",
       " 0.645363,\n",
       " 0.832631,\n",
       " 0.806425,\n",
       " 0.763769,\n",
       " 0.831374,\n",
       " 0.982121,\n",
       " 0.977066,\n",
       " 0.770371,\n",
       " 0.948824,\n",
       " 0.934494,\n",
       " 0.75701,\n",
       " 0.800951,\n",
       " 0.808329,\n",
       " 0.896092,\n",
       " 0.888645,\n",
       " 0.78187,\n",
       " 0.763952,\n",
       " 0.776694,\n",
       " 0.811295,\n",
       " 0.902919,\n",
       " 0.812299,\n",
       " 0.827825,\n",
       " 0.840483,\n",
       " 0.857353,\n",
       " 0.991692,\n",
       " 0.884341,\n",
       " 0.815497,\n",
       " 0.88126,\n",
       " 0.923972,\n",
       " 0.730855,\n",
       " 0.98997,\n",
       " 0.897422,\n",
       " 0.891954,\n",
       " 0.840507,\n",
       " 1.044919,\n",
       " 0.874459,\n",
       " 0.820483,\n",
       " 0.760026,\n",
       " 1.011325,\n",
       " 0.878352,\n",
       " 0.866075,\n",
       " 0.945124,\n",
       " 0.783335,\n",
       " 0.671936,\n",
       " 0.879985,\n",
       " 0.720635,\n",
       " 0.814363,\n",
       " 0.727875,\n",
       " 0.747074,\n",
       " 0.813435,\n",
       " 1.00457,\n",
       " 0.827801,\n",
       " 0.946341,\n",
       " 0.794543,\n",
       " 0.70469,\n",
       " 0.888348,\n",
       " 0.751411,\n",
       " 0.845623,\n",
       " 0.865527,\n",
       " 0.775954,\n",
       " 0.814479,\n",
       " 0.839136,\n",
       " 0.854484,\n",
       " 0.815892,\n",
       " 0.83764,\n",
       " 0.835407,\n",
       " 0.852634,\n",
       " 0.844621,\n",
       " 0.760344,\n",
       " 0.856381,\n",
       " 0.807398,\n",
       " 0.834401,\n",
       " 0.711175,\n",
       " 0.895979,\n",
       " 0.401886,\n",
       " 0.882843,\n",
       " 0.769458,\n",
       " 0.835161,\n",
       " 0.84444,\n",
       " 0.786159,\n",
       " 0.815099,\n",
       " 0.972389,\n",
       " 0.84018,\n",
       " 0.800245,\n",
       " 0.933844,\n",
       " 0.709275,\n",
       " 0.862745,\n",
       " 0.85508,\n",
       " 0.812991,\n",
       " 0.7166,\n",
       " 0.858268,\n",
       " 0.897424,\n",
       " 0.838156,\n",
       " 0.738271,\n",
       " 0.852116,\n",
       " 0.717115,\n",
       " 0.790316,\n",
       " 0.89449,\n",
       " 0.919212,\n",
       " 0.807689,\n",
       " 0.825515,\n",
       " 0.845989,\n",
       " 0.895979,\n",
       " 0.891256,\n",
       " 0.91823,\n",
       " 0.789146,\n",
       " 0.918542,\n",
       " 1.130799,\n",
       " 0.913641,\n",
       " 0.96033,\n",
       " 0.758309,\n",
       " 0.801927,\n",
       " 0.839544,\n",
       " 0.738416,\n",
       " 0.808349,\n",
       " 0.885229,\n",
       " 0.788808,\n",
       " 0.744839,\n",
       " 0.752151,\n",
       " 0.79697,\n",
       " 0.823261,\n",
       " 0.746674,\n",
       " 0.781989,\n",
       " 0.810675,\n",
       " 0.807508,\n",
       " 0.774448,\n",
       " 0.860376,\n",
       " 0.877798,\n",
       " 0.801854,\n",
       " 0.748556,\n",
       " 0.883185,\n",
       " 0.900792,\n",
       " 0.849581,\n",
       " 0.877752,\n",
       " 0.843945,\n",
       " 0.740356,\n",
       " 0.73991,\n",
       " 0.82538,\n",
       " 1.055835,\n",
       " 0.736382,\n",
       " 0.815816,\n",
       " 0.891385,\n",
       " 0.720605,\n",
       " 0.807942,\n",
       " 0.803524,\n",
       " 0.878571,\n",
       " 0.934601,\n",
       " 0.711776,\n",
       " 0.770745,\n",
       " 0.827191,\n",
       " 0.624547,\n",
       " 0.714316,\n",
       " 0.848927,\n",
       " 1.059104,\n",
       " 0.993379,\n",
       " 0.976905,\n",
       " 0.962889,\n",
       " 0.719535,\n",
       " 0.819729,\n",
       " 0.587529,\n",
       " 0.737244,\n",
       " 0.73389,\n",
       " 0.773434,\n",
       " 0.883035,\n",
       " 0.800442,\n",
       " 0.774473,\n",
       " 0.719047,\n",
       " 0.673789,\n",
       " 0.890901,\n",
       " 0.764871,\n",
       " 0.846384,\n",
       " 0.834675,\n",
       " 1.047016,\n",
       " 0.9502,\n",
       " 0.822676,\n",
       " 0.852669,\n",
       " 1.04015,\n",
       " 0.81182,\n",
       " 0.946274,\n",
       " 0.793698,\n",
       " 0.819162,\n",
       " 0.803064,\n",
       " 0.507558,\n",
       " 0.78899,\n",
       " 0.709399,\n",
       " 0.888348,\n",
       " 1.059389,\n",
       " 1.074994,\n",
       " 0.702682,\n",
       " 0.676618,\n",
       " 0.77684,\n",
       " 1.061588,\n",
       " 0.835255,\n",
       " 0.82502,\n",
       " 0.743507,\n",
       " 0.870258,\n",
       " 0.853465,\n",
       " 0.920987,\n",
       " 0.744872,\n",
       " 0.722493,\n",
       " 0.775288,\n",
       " 0.867448,\n",
       " 0.679065,\n",
       " 0.905352,\n",
       " 0.736269,\n",
       " 0.77987,\n",
       " 0.765892,\n",
       " 0.88586,\n",
       " 0.876255,\n",
       " 0.814319,\n",
       " 0.909604,\n",
       " 1.115021,\n",
       " 0.887433,\n",
       " 0.893006,\n",
       " 0.773343,\n",
       " 0.786334,\n",
       " 0.819507,\n",
       " 0.862721,\n",
       " 0.998175,\n",
       " 0.797506,\n",
       " 0.818178,\n",
       " 0.664167,\n",
       " 0.818487,\n",
       " 0.836864,\n",
       " 0.855583,\n",
       " 0.898221,\n",
       " 0.815737,\n",
       " 0.786478,\n",
       " 0.749065,\n",
       " 0.926725,\n",
       " 0.796873,\n",
       " 0.757338,\n",
       " 0.724419,\n",
       " 0.770261,\n",
       " 0.988842,\n",
       " 0.805771,\n",
       " 0.77932,\n",
       " 0.799656,\n",
       " 0.757297,\n",
       " 0.822683,\n",
       " 0.991722,\n",
       " 0.788405,\n",
       " 0.850891,\n",
       " 0.83001,\n",
       " 0.793225,\n",
       " 0.764368,\n",
       " 0.878054,\n",
       " 0.836281,\n",
       " 0.865508,\n",
       " 0.760663,\n",
       " 0.81321,\n",
       " 0.785217,\n",
       " 0.896605,\n",
       " 0.822329,\n",
       " 0.894631,\n",
       " 0.702961,\n",
       " 0.882059,\n",
       " 0.877833,\n",
       " 0.699649,\n",
       " 0.801444,\n",
       " 0.835556,\n",
       " 0.807387,\n",
       " 0.878428,\n",
       " 0.776328,\n",
       " 1.019733,\n",
       " 0.732329,\n",
       " 1.030255,\n",
       " 0.808695,\n",
       " 0.725647,\n",
       " 0.757394,\n",
       " 0.749846,\n",
       " 0.824796,\n",
       " 0.73383,\n",
       " 0.841339,\n",
       " 0.782033,\n",
       " 0.781446,\n",
       " 0.834769,\n",
       " 0.875162,\n",
       " 0.889771,\n",
       " 0.872438,\n",
       " 0.832038,\n",
       " 0.7854,\n",
       " 0.802824,\n",
       " 1.017536,\n",
       " 0.882306,\n",
       " 0.779188,\n",
       " 0.930093,\n",
       " 0.870974,\n",
       " 0.783129,\n",
       " 0.786885,\n",
       " 0.688591,\n",
       " 0.71477,\n",
       " 0.80762,\n",
       " 0.889364,\n",
       " 0.758815,\n",
       " 0.839047,\n",
       " 0.841675,\n",
       " 0.748085,\n",
       " 0.840179,\n",
       " 0.823924,\n",
       " 0.754132,\n",
       " 0.687546,\n",
       " 0.981316,\n",
       " 0.730815,\n",
       " 0.940325,\n",
       " 0.693979,\n",
       " 0.65333,\n",
       " 1.046482,\n",
       " 0.94226,\n",
       " 0.97588,\n",
       " 0.948294,\n",
       " 0.869978,\n",
       " 0.816008,\n",
       " 0.601368,\n",
       " 0.912323,\n",
       " 0.870812,\n",
       " 0.680252,\n",
       " 0.896571,\n",
       " 0.971575,\n",
       " 0.878624,\n",
       " 0.808467,\n",
       " 0.797583,\n",
       " 0.798294,\n",
       " 0.847437,\n",
       " 0.881402,\n",
       " 0.873567,\n",
       " 0.814292,\n",
       " 0.793718,\n",
       " 0.903525,\n",
       " 0.836912,\n",
       " 0.880595,\n",
       " 0.838516,\n",
       " 0.892212,\n",
       " 0.938779,\n",
       " 0.753432,\n",
       " 0.895139,\n",
       " 0.781513,\n",
       " 0.918805,\n",
       " 0.872784,\n",
       " 0.76697,\n",
       " 0.735864,\n",
       " 0.64561,\n",
       " 0.819477,\n",
       " 0.793166,\n",
       " 0.899613,\n",
       " 1.017346,\n",
       " 0.804393,\n",
       " 0.787746,\n",
       " 0.918011,\n",
       " 0.863711,\n",
       " 0.821155,\n",
       " 0.842324,\n",
       " 0.680527,\n",
       " 0.827987,\n",
       " 0.823338,\n",
       " 0.923363,\n",
       " 0.915466,\n",
       " 0.891139,\n",
       " 0.769702,\n",
       " 0.82216,\n",
       " 0.734501,\n",
       " 0.881379,\n",
       " 0.737692,\n",
       " 0.687965,\n",
       " 0.956372,\n",
       " 0.866296,\n",
       " 0.784222,\n",
       " 0.87856,\n",
       " 0.755888,\n",
       " 0.82562,\n",
       " 0.916795,\n",
       " 0.797665,\n",
       " 0.808948,\n",
       " 0.789865,\n",
       " 0.819191,\n",
       " 0.805177,\n",
       " 0.859116,\n",
       " 0.780616,\n",
       " 0.948727,\n",
       " 0.705965,\n",
       " 0.810254,\n",
       " 0.873847,\n",
       " 0.899757,\n",
       " 0.972222,\n",
       " 0.813867,\n",
       " 0.778485,\n",
       " 0.787234,\n",
       " 0.817159,\n",
       " 0.77739,\n",
       " 0.548561,\n",
       " 0.759103,\n",
       " 0.770868,\n",
       " 0.728119,\n",
       " 0.683874,\n",
       " 0.788509,\n",
       " 0.85748,\n",
       " 0.828152,\n",
       " 0.835204,\n",
       " 0.860695,\n",
       " 0.805356,\n",
       " 0.754088,\n",
       " 0.801092,\n",
       " 0.820301,\n",
       " 0.791505,\n",
       " 0.749915,\n",
       " 0.90593,\n",
       " 0.740522,\n",
       " 0.76096,\n",
       " 0.975054,\n",
       " 1.002633,\n",
       " 0.910667,\n",
       " 0.703812,\n",
       " 0.8447,\n",
       " 0.840309,\n",
       " 0.879979,\n",
       " 0.860291,\n",
       " 1.029405,\n",
       " 0.950367,\n",
       " 0.94194,\n",
       " 0.820937,\n",
       " 0.807927,\n",
       " 0.892665,\n",
       " 0.923645,\n",
       " 0.806824,\n",
       " 0.833751,\n",
       " 0.994026,\n",
       " 0.90729,\n",
       " 0.691984,\n",
       " 0.926891,\n",
       " 0.858461,\n",
       " 0.883997,\n",
       " 0.955585,\n",
       " 0.797356,\n",
       " 0.894991,\n",
       " 0.963732,\n",
       " 0.78493,\n",
       " 0.802398,\n",
       " 0.853152,\n",
       " 0.789164,\n",
       " 0.8531,\n",
       " 0.831741,\n",
       " 0.911687,\n",
       " 0.734517,\n",
       " 0.835568,\n",
       " 0.849138,\n",
       " 0.824667,\n",
       " 0.864967,\n",
       " 0.928651,\n",
       " 0.859132,\n",
       " 0.852653,\n",
       " 0.774389,\n",
       " 0.815871,\n",
       " 0.932231,\n",
       " 0.754261,\n",
       " 0.867548,\n",
       " 0.828647,\n",
       " 0.917778,\n",
       " 0.812784,\n",
       " 0.735837,\n",
       " 0.863403,\n",
       " 0.884441,\n",
       " 0.914381,\n",
       " 0.865467,\n",
       " 0.864299,\n",
       " 0.961071,\n",
       " 0.981088,\n",
       " 0.951733,\n",
       " 0.90833,\n",
       " 0.862435,\n",
       " 0.845251,\n",
       " 0.767196,\n",
       " 0.788264,\n",
       " 0.826416,\n",
       " 0.73819,\n",
       " 0.820713,\n",
       " 0.846962,\n",
       " 0.980879,\n",
       " 0.749998,\n",
       " 0.706727,\n",
       " 0.969841,\n",
       " 0.884271,\n",
       " 0.787181,\n",
       " 0.882009,\n",
       " 0.813026,\n",
       " 0.85397,\n",
       " 0.825772,\n",
       " 0.886485,\n",
       " 0.753978,\n",
       " 0.812227,\n",
       " 0.855652,\n",
       " 0.972295,\n",
       " 0.746238,\n",
       " 0.756493,\n",
       " 0.737296,\n",
       " 0.845881,\n",
       " 1.025793,\n",
       " 0.974746,\n",
       " 1.063419,\n",
       " 1.062794,\n",
       " 0.824112,\n",
       " 0.821836,\n",
       " 0.758799,\n",
       " 0.836124,\n",
       " 0.915996,\n",
       " 0.807042,\n",
       " 0.784172,\n",
       " 0.792167,\n",
       " 0.770228,\n",
       " 0.820156,\n",
       " 0.861534,\n",
       " 0.631168,\n",
       " 0.858756,\n",
       " 0.715922,\n",
       " 0.853369,\n",
       " 0.813897,\n",
       " 0.776655,\n",
       " 0.857521,\n",
       " 0.866009,\n",
       " 0.846563,\n",
       " 0.985689,\n",
       " 1.011185,\n",
       " 0.693785,\n",
       " 0.801149,\n",
       " 0.826849,\n",
       " 0.835762,\n",
       " 0.971628,\n",
       " 0.896773,\n",
       " 0.831541,\n",
       " 0.929776,\n",
       " 0.594069,\n",
       " 0.949852,\n",
       " 0.789513,\n",
       " 0.75166,\n",
       " 0.716327,\n",
       " 0.804725,\n",
       " 0.89518,\n",
       " 0.755249,\n",
       " 0.868962,\n",
       " 0.641786,\n",
       " ...]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__sim_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
